Кейс по написанию парсера для wildberries.ru

Итоги работы парсера:
из 3968 товаров, собрал 4307 карточек. Пропало 339 карточек.

Буду с этим разбираться 

В моём примере сможете найти следующее:

* Как оптимизировать кол-во запросов на сервер
* Ассинхронный подход
* Использование прокси
* Получение и использование cookie фалйов
* Получение cookie после выполнения js функций в браузере

P.S базу данных специально выгрузил. Куки храняться не долго, прокси ещё меньшге. Вдруг кому то пригодиться

Maind MAP
Чтобы создать иделаьное творение нужно много времени и учесть много деталей.
Ниже список того что нужно реализовать/проверить:

Критически важно!
* Логирование
* Понять от куда 404 ссылки
* Исправить работу с cookie. Если они уже есть и перестали работать, нужно обновить 

Прочее интересное
Проверить стоимость: Регион, Устройство, вб банк**
Проверить работает ли везде эти 2 %
Понять от куда эти 2 процента
Понять зависит ли описание от хар. карточки товара
Получить первые печеньки(cookies)
Региональность dest
Проверить кол-во выгруженных карточек, проверить дубли
while repeat serach +
переписать qty и qty SIZE
сделать блок схему
создание бд +
добавить сохранение в файл, когда url 404
если куки умер то обновить его 
функция save -> переделать структуру сохранение card 

обработка 404 ошибка

!!! Нужно сделать сбор карточек по их id так как в карточках есть ещё full colors -> который нужно тоже получить 






  Ниже добавляю дневник как я русуждал в начале. Получилось забавно.
Спам да и только )
В мыслях много интересного, что можно улучшить и переделать. 

После прочтения товары "**пальто из натуральной шерсти**"
Сразу вопрос оригинальности. Так ка выдача wb уникальна под разный регион. Возможно и локации

У нас бесконечный скроллинг. Вопрос как понять что кол-тов меняется?


Одинаковые запросы которые urlUncode 2 раза
отличие только во времени запроса

**WB гении))** 

мы получаем 8 ответов и ответ в request paylod -> в первые вижу такой подход)) 

Нужно проверить, что на 8 карточек становиться больше 


Стандартный прикол с подменой вэб сервера на получения img) 
У разного товара будет разный url сервера для хранение фото. Проходил такое было)


Нужно понять, как он понимает какой элемент грузить дальше. Ведь в url нет точного id или count

Я понял) Новый запрос с уникальным временем -> уникальный ответ. 1 ответ 1 товар.

Логика ясна. иду разворачивать проект

иду на свой репозиторий

Возвращаясь выше к вопросу сервера изображений, уже есть регулярное выражение) 


тут я воспользуюсь AI, чтобы в ручную не переписывать все заголовки. 
Единственное скажу, что важно не использовать заголовок br иначе запрос слетает

попробую грубой силой запрос послать, вдруг выйдет. Раньше запросы на wb по другому формировались. Сейчас новая фича с request payload

Это же POST запрос...
Вот тут интересно, зачем WB перегружают свой же сервер. Ведь заголовки тела такие же как и сам запрос. Проще было через GET. Странное решение их разработчиков. Возможно какая то защита. Но чет сомневаюсь. 

Вот к чему приводит использование AI на продакшене)

Пробую грубую силу через requests

тут у меня вопрос, как же формируется их requst paylod. От куда он взялся в запросе. Проверю на offline запросе

Ага, значит наш квери стринг это дуль get запроса из url
А reqest это тело запроса. агась...

пока запутался 

на всякий случай проверяю js вдруг там данные

нашел где грузятся первые данные.
Иду смотреть их кол-во в json

сейчас буду ожидатиь повторного get запроса


Если вопрос зачем я так страдаю, когда можно сразу грузить selenium и пролистывать пока скролиться, то всё просто. Не эффективно. Самый быстрое решение на прямую через requests, точнее через прямой запрос. Но антидетект покажет запрет. Придется эмулировать. Но даже когда мы эмулируем, важна скорость. Для этого нужно подключать js, а для этого нужны все запросы которые обмениваются с сервером 

Я получил первоисточник данных. Осталось понять хватит ли только его. Как проверить? По img. Так как получение img с разных серверов, то буду искать id img и смотреть, если он есть то победа. Если его нет, то буду думать) 
Пойду проверю в свой исходнике как раньше всё работало. Так как мой исходник где-то годичной давности. За год получения карточки поменялось. Либо другая система ранжирования отличная от получения для конкретного бренда


Много данных и они хранятся уже в карточке товара. 
Первый этап пройден, мы знаем id карточек.
Нужно понять как получается вторая ссылка. На что срабатывает js код 

На этот раз просто GET запрос и я не попадусь на свои же ошибки с POST запросом 

Они даже используют AB тесты своих страниц. +респект ВБ, что анализируют и улучшают сервис 

Теперь понятно ват наша конечная ссылка для получения первоначального каталога по запросу:
https://www.wildberries.ru/__internal/u-search/exactmatch/ru/common/v18/search?ab_testing=false&appType=1&curr=rub&dest=-3351953&hide_dtype=9&hide_vflags=4294967296&lang=ru&page=3&query=пальто+из+натуральной+шерсти+page=21&resultset=catalog&sort=popular&spp=30&suppressSpellcheck=false

здесь меняется наш page=
Использую снова AI для генерации нашего body, тела запроса, чтобы не переписывать в ручную

Логично что нет редиректов, ведь у нас 200 ответ

что за статус такой 498

без cookie отправлять запрос гениально) 

Честно не ожидал что он мне вот так вот запросто отдаст запрос обратно. 
Мне нужно отойти, поставлю запись на паузу и после продолжу с этого же места 

Хочу понять кол-во товара
Есть ли ранжирование по региональности. 

изначально товаров 3423

!!!Нашёл региональную зависимость. Переменная dest
!!!Важно что если убрать "из", из запроса, то мы получаем -956 позиций

!!! Важно 1 товар - много цен 

Осознал, что на цену может влиять, регион, устройство, авторизация, вб банк?

У нас есть цена bace и product. А есть цена продажи, со скидкой ~2% если есть кашелёк


По цене. У нас нет конечной цены. Возможно она считается автоматом с учётом 2%

!!! У нас есть gif во время просомтра


2) Из своего же репозитория делаю git WB
я не знаю на каком из условно 100 серверов лежит картинка. Для перебора
нужно ~30 запросов * ~15 картинок ~ 5000 товара = 1.500.000 запросов
не порядок. Нужно искать сервера
нашёл ссылку -> которая формирует наш прайс
https://static-basket-01.wbbasket.ru/vol1/global-payment/default-payment.json
2 варианы, не атворизован 2%. 3% при Клуб ВБ

Просматривая .js наткнулся на swith который выбирает сервер. Как оказалось это 
промежуток который часть Артикула товара. Это был мега рандом, что я попаду на такую разгадку, но это круто. Теперь я знаю на каком сервере храниться карточка товара. 

Нужно понять как работает эта же схема но с изображеним. 

как получать полную ссылку для card научился

теперь понять как получать ссылки на img's

при 5000 товара:
50 запросов на 100 карточек
10.000 запросов на обработку 
если 5 проксей -> 2000 запросов 
если запросы каждые 500ms
реально 1000 секунд -> ~17 минут парсинга 

Логика работы

Через SEARH получаем все id карточек
По 100 id  DETAIL карточек мы получаем данные -> по 1 id идем по CARD

Когда мы выполнили все SEARH + все DETAIL и все CARD -> у нас может быть доп id из CARD

Нужно ещё раз пройтись по DETAIL + CARD

  
  
